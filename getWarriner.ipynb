{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same thing as getWhissell but using the emotion dictionary from Warriner at al 2013. They have many more words (almost 14,000) but no function words, and they use lemmas on the assumption that only a few plurals are used more often than singulars and as such should not have very distinct emotional profiles. So processing this dictionary for scores will be a bit different. Their three vectors are Valence, Arousal, and Dominance. Dominance is not related to Whissell's Imagery so that third score will have to be neglected for now (though they discuss imageability on p. 1199. Brysbaert et al 2014 provides concreteness scores, and it is there that they discuss choosing lemmas over other forms. For that list, which they don't say how it might relate to this one, they include plurals that are used as different parts of speech or that are used more frequently than the singular [eyes]). So as a first guess lets lemmatize the text, not run a stop list but look up each word and keep it on the Nonelist for now. Lemmatization has its own pitfalls so we need to keep an eye on that. Valence (EE) mean is 5.06, Activation (AA) is 4.21, and Dominance (DD) is 5.18 (on a scale from 1-9, lowest-highest). I will try using SpaCy instead of NLTK, for speed and so it will scale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Rainsford, asked, \"What island is it?\")\n",
      "(Rainsford, asked, \"The old charts call it Ship-Trap Island,'\")\n",
      "(imagination, said, \"Pure imagination,\")\n",
      "(imagination, said, \"One superstitious sailor can taint the whole ship's company with his fear.\")\n",
      "(he, thought, \"It's so dark,\")\n",
      "(he, thought, \"Where there are pistol shots, there are men. Where there are men, there is food,\")\n",
      "(he, said, \"It is a very great pleasure and honor to welcome Mr. Sanger Rainsford, the celebrated hunter, to my home.\")\n",
      "(he, said, \"So am I.\")\n",
      "(he, said, \"Come,\")\n",
      "(he, said, \"we shouldn't be chatting here. We can talk later. Now you want clothes, food, rest. You shall have them. This is a most -- restful spot.\")\n",
      "(Follow Ivan, said, \"Follow Ivan, if you please, Mr. Rainsford,\")\n",
      "(Follow Ivan, said, \"I was about to have my dinner when you came. I'll wait for you. You'll find that my clothes will fit you, I think.\")\n",
      "(he, suggested, \"You'll have a cocktail, Mr. Rainsford,\")\n",
      "(Half, said, \"We do our best to preserve the amenities of civilization here. Please forgive any lapses. We are well off the beaten track, you know. Do you think the champagne has suffered from its long ocean trip?\")\n",
      "(he, said, \"No. You are wrong, sir. The Cape buffalo is not the most dangerous big game.\")\n",
      "(he, said, \"Here in my preserve on this island,\")\n",
      "(he, said, \"I hunt more dangerous game.\")\n",
      "(Rainsford, asked, \"What have you imported, general?\")\n",
      "(Rainsford, asked, \"Tigers?\")\n",
      "(he, said, \"No,\")\n",
      "(he, said, \"Hunting tigers ceased to interest me some years ago. I exhausted their possibilities, you see. No thrill left in tigers, no real danger. I live for danger, Mr. Rainsford.\")\n",
      "(he, said, \"I had no wish to go to pieces,\")\n",
      "(he, said, \"I must do something. Now, mine is an analytical mind, Mr. Rainsford. Doubtless that is why I enjoy the problems of the chase.\")\n",
      "(host, saying, \"It came to me as an inspiration what I must do,\")\n",
      "(he, said, \"I had to invent a new animal to hunt,\")\n",
      "(he, said, \"A new animal? You're joking.\")\n",
      "(fellow, said, \"My dear fellow,\")\n",
      "(fellow, said, \"there is one that can.\")\n",
      "(he, said, \"How extraordinarily droll you are!\")\n",
      "(he, said, \"One does not expect nowadays to find a young man of the educated class, even in America, with such a naive, and, if I may say so, mid-Victorian point of view. It's like finding a snuffbox in a limousine. Ah, well, doubtless you had Puritan ancestors. So many Americans appear to have had. I'll wager you'll forget your notions when you go hunting with me. You've a genuine new thrill in store for you, Mr. Rainsford.\")\n",
      "(he, said, \"They indicate a channel,\")\n",
      "(he, said, \"where there's none; giant rocks with razor edges crouch like a sea monster with wide-open jaws. They can crush a ship as easily as I crush this nut.\")\n",
      "(he, said, \"Oh, yes,\")\n",
      "(he, said, \"I have electricity. We try to be civilized here.\")\n",
      "(he, said, \"Dear me, what a righteous young man you are! I assure you I do not do the thing you suggest. That would be barbarous. I treat these visitors with every consideration. They get plenty of good food and exercise. They get into splendid physical condition. You shall see for yourself tomorrow.\")\n",
      "(he, said, \"To date I have not lost,\")\n",
      "(he, added, \"I don't wish you to think me a braggart, Mr. Rainsford. Many of them afford only the most elementary sort of problem. Occasionally I strike a tartar. One almost did win. I eventually had to use the dogs.\")\n",
      "(lot, observed, \"A rather good lot, I think,\")\n",
      "(lot, observed, \"They are let out at seven every night. If anyone should try to get into my house -- or out of it -- something extremely regrettable would occur to him.\")\n",
      "(general, said, \"Ennui. Boredom.\")\n",
      "(general, explained, \"The hunting was not good last night. The fellow lost his head. He made a straight trail that offered no problems at all. That's the trouble with these sailors; they have dull brains to begin with, and they do not know how to get about in the woods. They do excessively stupid and obvious things. It's most annoying. Will you have another glass of Chablis, Mr. Rainsford?\")\n",
      "(General, said, \"General,\")\n",
      "(General, said, \"I wish to leave this island at once.\")\n",
      "(he, said, \"No, general,\")\n",
      "(he, said, \"I will not hunt.\")\n",
      "(he, said, \"As you wish, my friend,\")\n",
      "(he, said, \"The choice rests entirely with you. But may I not venture to suggest that you will find my idea of sport more diverting than Ivan's?\")\n",
      "(fellow, said, \"My dear fellow,\")\n",
      "(fellow, said, \"have I not told you I always mean what I say about hunting? This is really an inspiration. I drink to a foeman worthy of my steel -- at last.\")\n",
      "(general, said, \"You'll find this game worth playing,\")\n",
      "(general, said, \"Your brain against mine. Your woodcraft against mine. Your strength and stamina against mine. Outdoor chess! And the stake is not without value, eh?\")\n",
      "(Rainsford, thinking, \"My sloop will place you on the mainland near a town.\")\n",
      "(Rainsford, thinking, \"Oh, you can trust me,\")\n",
      "(he, said, \"Ivan,\")\n",
      "(he, said, \"will supply you with hunting clothes, food, a knife. I suggest you wear moccasins; they leave a poorer trail. I suggest, too, that you avoid the big swamp in the southeast corner of the island. We call it Death Swamp. There's quicksand there. One foolish fellow tried it. The deplorable part of it was that Lazarus followed him. You can imagine my feelings, Mr. Rainsford. I loved Lazarus; he was the finest hound in my pack. Well, I must beg you to excuse me now. I always take a siesta after lunch. You'll hardly have time for a nap, I fear. You'll want to start, no doubt. I shall not follow till dusk. Hunting at night is so much more exciting than by day, don't you think? Au revoir, Mr. Rainsford, au revoir.\")\n",
      "(he, said, \"I must keep my nerve. I must keep my nerve,\")\n",
      "(he, thought, \"I have played the fox, now I must play the cat of the fable.\")\n",
      "(Swam, said, \"Swam,\")\n",
      "(Swam, said, \"I found it quicker than walking through the jungle.\")\n",
      "(he, said, \"I congratulate you,\")\n",
      "(he, said, \"You have won the game.\")\n",
      "(he, said, \"I am still a beast at bay,\")\n",
      "(he, said, \"Get ready, General Zaroff.\")\n",
      "(he, said, \"I see,\")\n",
      "(he, said, \"Splendid! One of us is to furnish a repast for the hounds. The other will sleep in this very excellent bed. On guard, Rainsford.\")\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import textacy\n",
    "import re\n",
    "#import matplotlib.pyplot as plt\n",
    "#from statistics import mean\n",
    "\n",
    "targetDoc = \"texts/mdg.txt\"     # the text to analyze (relative path)\n",
    "#targetWord = \"birds\"               # the word type you want to score\n",
    "#targetWindow = 6                  # this is tokens before and after target\n",
    "\n",
    "#nlp = spacy.load('en')\n",
    "#doc = nlp(u'Apple is looking at buying U.K. startup for $1 billion')\n",
    "document = open(targetDoc).read()\n",
    "document = re.sub(\"('\\s|\\s')\",\" \", document)           #odd thing for Waves.text, too many single quotes\n",
    "textacy.preprocess.normalize_whitespace(document)\n",
    "textacy.preprocess_text(document, lowercase=True, no_punct=False)\n",
    "#textacy.text_utils.KWIC(document, 'on', window_width=35)\n",
    "doc = textacy.Doc(document)\n",
    "\n",
    "quotes = textacy.extract.direct_quotations(doc)\n",
    "for quote in quotes:\n",
    "    print(quote)\n",
    "\n",
    "#for sent in doc.sents:\n",
    "#    for word in sent:\n",
    "#        if word.text == targetWord:\n",
    "#            print(sent)  #prints sentences that have the target word in them\n",
    "            \n",
    "\n",
    "#trips = textacy.extract.subject_verb_object_triples(doc) # makes a generator; transitives only\n",
    "#for item in trips:\n",
    "#    print(item)\n",
    "\n",
    "#for sent in doc.sents:\n",
    "#    start_i = sent[0].i\n",
    "\n",
    "\n",
    "#    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    " #           token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    c = nltk.ConcordanceIndex(doc_text.tokens, key = lambda s: s.lower())\n",
    "basically indexes the words for every token of the text. The 'offset' function returns the list of token offset positions for a word. (c.\\_tokens) is the list of words, so a subscript of that will access the exact word at that position. \n",
    "Next, open the DA file and read it into a dictionary. Each line is split so the word is the key and the three Whissell numbers is the value. Lookup is simple: get(key) returns value: daffect.get(c.\\_tokens[335]). Then split the value strings into three floating point numbers because math."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = nltk.ConcordanceIndex(doc_text.tokens, key = lambda s: s.lower())\n",
    "locations = c.offsets(targetWord)\n",
    "\n",
    "with open(\"texts/DAL.txt\") as dictionary_affect_file:\n",
    "   daffect = dict(line.rstrip().split(\",\", 1) for line in dictionary_affect_file)\n",
    "\n",
    "alleevals = []                   #declare lists of vals for every token found in text\n",
    "allaavals = []\n",
    "alliivals = []\n",
    "allNonelist = []                 # keep all nonelist for token report\n",
    "allAvgeevals = []                # keep list of avg vals for plotting\n",
    "allAvgaavals = []\n",
    "allAvgiivals = []\n",
    "\n",
    "for location in locations:       #iterate over list of concordance hit offsets\n",
    "    print (c._tokens[location], \"offset =\", location)\n",
    "    phrase = []                  #keep a list of tokens in the phrase\n",
    "    nonelist = []                #new val lists for each interation of a location\n",
    "    eevals = []\n",
    "    aavals = []\n",
    "    iivals = []     \n",
    "    for i in range(0-targetWindow, 1+targetWindow):        #iterate over range from target offset, range extends up to but no including\n",
    "        #print (c._tokens[location+i], daffect.get(c._tokens[location+i]))\n",
    "        #print (c._tokens[location-i], daffect.get(c._tokens[location-i]))\n",
    "        phrase.append(c._tokens[location+i]) \n",
    "         \n",
    "        if daffect.get(c._tokens[location+i]) is None:\n",
    "            nonelist.append(c._tokens[location+i])         # prepare report of words not in DAL\n",
    "        else:\n",
    "            eeval, aaval, iival = daffect.get(c._tokens[location+i]).split(\",\")\n",
    "            eevals.append(float(eeval))                    # have to convert these to fp numbers\n",
    "            aavals.append(float(aaval))\n",
    "            iivals.append(float(iival))\n",
    "            #print (c._tokens[location+i], \"eevals = \", eevals)\n",
    "            #print (\"eevals length =\",len(eevals))\n",
    "            \n",
    "    alleevals.extend(eevals)                 #add vals from this token onto alltokens list\n",
    "    allaavals.extend(aavals)                 #to calculate mean of alltokens \n",
    "    alliivals.extend(iivals)                 #problem: target word gets added each time\n",
    "    allNonelist.extend(nonelist)\n",
    "    #print (alleevals) #check to see\n",
    "    \n",
    "    avgeevals = round(mean(eevals), 4)       # rounded to 4 decimal places like Whissell\n",
    "    avgaavals = round(mean(aavals), 4)       # rounded to 4 decimal places like Whissell\n",
    "    avgiivals = round(mean(iivals), 2)       # rounded to 2 decimal places like Whissell\n",
    "    \n",
    "    allAvgeevals.append(avgeevals - 1.85)  # .extend causes a TypeError: 'float' object is not iterable\n",
    "    allAvgaavals.append(avgaavals - 1.67)  # We subtract the balanced corpus mean to give variance\n",
    "    allAvgiivals.append(avgiivals - 1.525)\n",
    "    \n",
    "    # here follow the token reports: all the words, the No Vals list, and the scores\n",
    "    print (\" \".join(word for word in phrase))\n",
    "    print (\"No Values for\", nonelist)\n",
    "    print (\"EE =\", avgeevals, \"AA =\", avgaavals, \"II =\", avgiivals, \"\\n\") \n",
    "\n",
    "hitratio = 100*(round(len(alleevals) / (len(alleevals) + len(allNonelist)), 3))\n",
    "meanTotaleevals = round(mean(alleevals), 4)\n",
    "meanTotalaavals = round(mean(allaavals), 4)\n",
    "meanTotaliivals = round(mean(alliivals), 2)\n",
    "\n",
    "# here follow the type reports: the target word, its score, and the hit ration. Need anything else?\n",
    "print (\"Type Means for\", targetWord) \n",
    "print (\"EE =\", meanTotaleevals)\n",
    "print (\"AA =\", meanTotalaavals)\n",
    "print (\"II =\", meanTotaliivals)\n",
    "print (\"No values for\", list(sorted(set(allNonelist))))\n",
    "print (\"Hit Ratio = %\",hitratio)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to display values for each word plotted over the book. Really need to follow her methodology as first guesstimate. \"The mean of all values for a sample characterizes the sample as a whole.\" Whissell 2009, 515. She takes the mean for all word sets involved. For _Much Ado about Nothing_ she takes total speeches from each character (p. 516) and compares values to compare characters. In her other test she examines a police-involved shooting in Ireland, the speech of the shooter and of the later police report. There she focuses on the extreme ends of the emotion scales, and the method is not quite clear. She refers to a 2007 article on \"Ruth\" that clarifies nothing--she compares to \"normative\" numbers of strong emotion words in her 1998 corpus but does not provide those numbers anywhere that I found. \n",
    "Display: from DAL: on a balanced corpus, mean ee is 1.85, with an sd of .36. So, if we subtract 1.85 from our eevals we will get the distance positive or negative from the mean. Lets try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(allAvgeevals, 'g', allAvgaavals, 'r', allAvgiivals, 'orange')\n",
    "plt.suptitle(targetWord)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
