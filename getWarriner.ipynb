{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same thing as getWhissell but using the emotion dictionary from Warriner at al 2013. They have many more words (almost 14,000) but no function words, and they use lemmas on the assumption that only a few plurals are used more often than singulars and as such should not have very distinct emotional profiles. So processing this dictionary for scores will be a bit different. Their three vectors are Valence, Arousal, and Dominance. Dominance is not related to Whissell's Imagery so that third score will have to be neglected for now (though they discuss imageability on p. 1199. Brysbaert et al 2014 provides concreteness scores, and it is there that they discuss choosing lemmas over other forms. For that list, which they don't say how it might relate to this one, they include plurals that are used as different parts of speech or that are used more frequently than the singular [eyes]). So as a first guess lets lemmatize the text, not run a stop list but look up each word and keep it on the Nonelist for now. Lemmatization has its own pitfalls so we need to keep an eye on that. Valence (EE) mean is 5.06, Activation (AA) is 4.21, and Dominance (DD) is 5.18 (on a scale from 1-9, lowest-highest). I will try using SpaCy instead of NLTK, for speed and so it will scale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38, 95]\n",
      "['bernard', 'hang', 'quiver', 'hang', 'loop', 'light', 'slab', 'pale', 'yellow', 'say', 'susan']\n",
      "['bernard', 'bead', 'water', 'drop', 'white', 'light', 'pass', 'house', 'house', 'like', 'friar']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import textacy\n",
    "import re\n",
    "\n",
    "targetDoc = \"texts/waves-par-lemmas.txt\"     # the text to analyze (relative path), already lemmatized\n",
    "targetWord = \"light\"               # the word type you want to score\n",
    "targetWindow = 5                  # this is tokens before and after target\n",
    "#outFile = \"texts/mdg-lemmas.txt\"\n",
    "\n",
    "#file = open(outFile, \"w\")\n",
    "\n",
    "document = open(targetDoc).read().split()\n",
    "numbered = enumerate(document)\n",
    "\n",
    "hitlist = []               #make a list of hits\n",
    "for i, j in numbered:\n",
    "    if j == targetWord:\n",
    "        hitlist.append(i)\n",
    "print(hitlist)        \n",
    "for hit in hitlist:\n",
    "    phrase = []\n",
    "    for index, word in enumerate(document):   # why can't we reuse numbered? This can't be the best way\n",
    "        if index >= (hit - targetWindow) and index <=  (hit + targetWindow):\n",
    "            phrase.append(word)\n",
    "    print(phrase)\n",
    "        \n",
    " \n",
    "      \n",
    "#file.close()\n",
    "\n",
    "#print(hitlist)\n",
    "#for hit in hitlist:\n",
    "#    phrase = []                  #keep a list of tokens in the phrase\n",
    "#    for j in range(hit-targetWindow, hit+targetWindow):\n",
    "#        if spaceDoc[j].is_alpha and spaceDoc[j].lemma_ != \"-PRON-\":\n",
    "#            #print(spaceDoc[j].lemma_)\n",
    "#            phrase.append(spaceDoc[j].lemma_)\n",
    "#    \n",
    "#    print(\" \".join(word for word in phrase))\n",
    "\n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp = spacy.load(\"en\")           #ok this works to get the ords and such. But there might be a better method.\n",
    "#spaceDoc = nlp(document)\n",
    "#hitlist = []                #make a list of hits\n",
    "#for t in spaceDoc:                   # t.is_alpha = not punctuation, t.sent = word's sentence\n",
    "#    if t.text == targetWord:\n",
    "#        hitlist.append(t.i)\n",
    "#print(hitlist)\n",
    "#for hit in hitlist:\n",
    "#    phrase = []                  #keep a list of tokens in the phrase\n",
    "#    for j in range(hit-targetWindow, hit+targetWindow):\n",
    "#        if spaceDoc[j].is_alpha and spaceDoc[j].lemma_ != \"-PRON-\":\n",
    "#            #print(spaceDoc[j].lemma_)\n",
    "#            phrase.append(spaceDoc[j].lemma_)\n",
    "#    \n",
    "#    print(\" \".join(word for word in phrase))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    spaCy is a text processing package in Python. It slurps up the text and does lot sof things to it, one thing being lemmatizations. textacy is a wrapper for spaCy that makes it simple to access lots of the data that Spacy makes. As you can see above, several things can be accomplished by a single line. Working on the whole novel The Waves, it takes a bout 15 seconds and some windup on the hard drive to do anything, so its a bit slow. On the other hand, it gets the stuff out in pretty good form. I installed spacy using Anaconda, then had to do textacy from the prompt using conda. The respective program documentations describes how to do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Rainsford, asked, \"What island is it?\")\n",
      "(Rainsford, asked, \"The old charts call it 'Ship-Trap Island,'\")\n",
      "(imagination, said, \"Pure imagination,\")\n",
      "(imagination, said, \"One superstitious sailor can taint the whole ship's company with his fear.\")\n",
      "(he, thought, \"It's so dark,\")\n",
      "(he, thought, \"Where there are pistol shots, there are men. Where there are men, there is food,\")\n",
      "(he, said, \"It is a very great pleasure and honor to welcome Mr. Sanger Rainsford, the celebrated hunter, to my home.\")\n",
      "(he, said, \"So am I.\")\n",
      "(he, said, \"Come,\")\n",
      "(he, said, \"we shouldn't be chatting here. We can talk later. Now you want clothes, food, rest. You shall have them. This is a most -- restful spot.\")\n",
      "(Follow Ivan, said, \"Follow Ivan, if you please, Mr. Rainsford,\")\n",
      "(Follow Ivan, said, \"I was about to have my dinner when you came. I'll wait for you. You'll find that my clothes will fit you, I think.\")\n",
      "(he, suggested, \"You'll have a cocktail, Mr. Rainsford,\")\n",
      "(Half, said, \"We do our best to preserve the amenities of civilization here. Please forgive any lapses. We are well off the beaten track, you know. Do you think the champagne has suffered from its long ocean trip?\")\n",
      "(he, said, \"No. You are wrong, sir. The Cape buffalo is not the most dangerous big game.\")\n",
      "(he, said, \"Here in my preserve on this island,\")\n",
      "(he, said, \"I hunt more dangerous game.\")\n",
      "(Rainsford, asked, \"What have you imported, general?\")\n",
      "(Rainsford, asked, \"Tigers?\")\n",
      "(he, said, \"No,\")\n",
      "(he, said, \"Hunting tigers ceased to interest me some years ago. I exhausted their possibilities, you see. No thrill left in tigers, no real danger. I live for danger, Mr. Rainsford.\")\n",
      "(he, said, \"I had no wish to go to pieces,\")\n",
      "(he, said, \"I must do something. Now, mine is an analytical mind, Mr. Rainsford. Doubtless that is why I enjoy the problems of the chase.\")\n",
      "(host, saying, \"It came to me as an inspiration what I must do,\")\n",
      "(he, said, \"I had to invent a new animal to hunt,\")\n",
      "(he, said, \"A new animal? You're joking.\")\n",
      "(fellow, said, \"My dear fellow,\")\n",
      "(fellow, said, \"there is one that can.\")\n",
      "(he, said, \"How extraordinarily droll you are!\")\n",
      "(he, said, \"One does not expect nowadays to find a young man of the educated class, even in America, with such a naive, and, if I may say so, mid-Victorian point of view. It's like finding a snuffbox in a limousine. Ah, well, doubtless you had Puritan ancestors. So many Americans appear to have had. I'll wager you'll forget your notions when you go hunting with me. You've a genuine new thrill in store for you, Mr. Rainsford.\")\n",
      "(he, said, \"They indicate a channel,\")\n",
      "(he, said, \"where there's none; giant rocks with razor edges crouch like a sea monster with wide-open jaws. They can crush a ship as easily as I crush this nut.\")\n",
      "(he, said, \"Oh, yes,\")\n",
      "(he, said, \"I have electricity. We try to be civilized here.\")\n",
      "(he, said, \"Dear me, what a righteous young man you are! I assure you I do not do the thing you suggest. That would be barbarous. I treat these visitors with every consideration. They get plenty of good food and exercise. They get into splendid physical condition. You shall see for yourself tomorrow.\")\n",
      "(he, said, \"To date I have not lost,\")\n",
      "(he, added, \"I don't wish you to think me a braggart, Mr. Rainsford. Many of them afford only the most elementary sort of problem. Occasionally I strike a tartar. One almost did win. I eventually had to use the dogs.\")\n",
      "(lot, observed, \"A rather good lot, I think,\")\n",
      "(lot, observed, \"They are let out at seven every night. If anyone should try to get into my house -- or out of it -- something extremely regrettable would occur to him.\")\n",
      "(general, said, \"Ennui. Boredom.\")\n",
      "(general, explained, \"The hunting was not good last night. The fellow lost his head. He made a straight trail that offered no problems at all. That's the trouble with these sailors; they have dull brains to begin with, and they do not know how to get about in the woods. They do excessively stupid and obvious things. It's most annoying. Will you have another glass of Chablis, Mr. Rainsford?\")\n",
      "(General, said, \"General,\")\n",
      "(General, said, \"I wish to leave this island at once.\")\n",
      "(he, said, \"No, general,\")\n",
      "(he, said, \"I will not hunt.\")\n",
      "(he, said, \"As you wish, my friend,\")\n",
      "(he, said, \"The choice rests entirely with you. But may I not venture to suggest that you will find my idea of sport more diverting than Ivan's?\")\n",
      "(fellow, said, \"My dear fellow,\")\n",
      "(fellow, said, \"have I not told you I always mean what I say about hunting? This is really an inspiration. I drink to a foeman worthy of my steel -- at last.\")\n",
      "(general, said, \"You'll find this game worth playing,\")\n",
      "(general, said, \"Your brain against mine. Your woodcraft against mine. Your strength and stamina against mine. Outdoor chess! And the stake is not without value, eh?\")\n",
      "(Rainsford, thinking, \"My sloop will place you on the mainland near a town.\")\n",
      "(Rainsford, thinking, \"Oh, you can trust me,\")\n",
      "(he, said, \"Ivan,\")\n",
      "(he, said, \"will supply you with hunting clothes, food, a knife. I suggest you wear moccasins; they leave a poorer trail. I suggest, too, that you avoid the big swamp in the southeast corner of the island. We call it Death Swamp. There's quicksand there. One foolish fellow tried it. The deplorable part of it was that Lazarus followed him. You can imagine my feelings, Mr. Rainsford. I loved Lazarus; he was the finest hound in my pack. Well, I must beg you to excuse me now. I always' take a siesta after lunch. You'll hardly have time for a nap, I fear. You'll want to start, no doubt. I shall not follow till dusk. Hunting at night is so much more exciting than by day, don't you think? Au revoir, Mr. Rainsford, au revoir.\")\n",
      "(he, said, \"I must keep my nerve. I must keep my nerve,\")\n",
      "(he, thought, \"I have played the fox, now I must play the cat of the fable.\")\n",
      "(Swam, said, \"Swam,\")\n",
      "(Swam, said, \"I found it quicker than walking through the jungle.\")\n",
      "(he, said, \"I congratulate you,\")\n",
      "(he, said, \"You have won the game.\")\n",
      "(he, said, \"I am still a beast at bay,\")\n",
      "(he, said, \"Get ready, General Zaroff.\")\n",
      "(he, said, \"I see,\")\n",
      "(he, said, \"Splendid! One of us is to furnish a repast for the hounds. The other will sleep in this very excellent bed. On guard, Rainsford.\")\n"
     ]
    }
   ],
   "source": [
    "quotes = textacy.extract.direct_quotations(doc)  #gets a rough list of quotations. Good first pass.\n",
    "for quote in quotes:\n",
    "    print(quote)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It quivers and\n",
      "hangs in a loop of light.  \n",
      "It has beads of water on it, drops of white light.  \n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:    #prints sentences that have the target word in them\n",
    "    for word in sent:\n",
    "        if word.text == targetWord:\n",
    "            print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This last command below creates a set of subj verb obj triples for each sentence. The catch is that it works only on transitive sentences. It's pretty good though. Ideally one would have it run on intransitives and transitives, then also on embedded clauses and possible even nonfinite clauses for a complete view of agency. But again its a good easy start. I should add that these textacy functions all create what Python calls a \"generator\". This is essentially an iterator without the iteration statement. The generator \"yields\" one item at a time, so it can be processed before the next item is presented. For example, the trips variable gives up one trip per go. The for-loop gets each trip in turn, does something to it, then gets the next one. In this case I am just printing, but we can do other things like make lists of all the transitive verbs or ones that take particular subjects, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = textacy.extract.subject_verb_object_triples(doc) # makes a generator; transitives only\n",
    "for item in trips:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the catch with getting lemmas is that to get the lemmas spacy needs the parse data, and to get that it needs the sentences, which of course need punctuation to detect. So we have to leave the punctuation in, run it into spacy, then find the target words, get their indexes, count forward and backward _excluding_ punctuation, get the lemmas for those indexes, then do the math."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
